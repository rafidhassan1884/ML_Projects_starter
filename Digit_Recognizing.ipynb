{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomRotation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-74bcfbcddd26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#for one hot encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnp_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxPool2D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     raise ImportError(\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[1;34m'Keras requires TensorFlow 2.2 or higher. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         'Install TensorFlow via `pip install tensorflow`')\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "#for one hot encoding\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "sns.set(style = \"dark\", context= \"notebook\", palette=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../input/digit-recognizer/train.csv\")\n",
    "test = pd.read_csv(\"../input/digit-recognizer/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[\"label\"].copy()\n",
    "train = train.drop(\"label\", axis = 1)\n",
    "\n",
    "train = train/255\n",
    "test = test/255\n",
    "\n",
    "train = train.values.reshape(-1, 28, 28, 1)\n",
    "test = test.values.reshape(-1, 28, 28, 1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#splitting data for training and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, y_train, test_size = 0.1, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37800, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4200, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val = to_categorical(y_val, num_classes=10)\n",
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37800, 28, 28, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4200, 28, 28, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD7CAYAAAClmULcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAPBUlEQVR4nO3dYWzT953H8Q945/S4YbmOLpFHUHKkDfJdT4oUujyYsqlGEzopEyfxIMgFdEic7kGVJ7kUubeUIMOq+mADIcGl3JOtUkonFCkNJlUy3XrdNKktau4eZK6AshBY4ktEEkROuZ06+38PqtLbiv9/iP23Dd/361ny7d/58JM+/dv++f/3BsdxHAEwZ2O1AwCoDsoPGEX5AaMoP2AU5QeMovyAUSWXf2ZmRj09Pdq1a5d6enp08+bNMsQC4LcNpe7zHzhwQHv27NHu3bv1zjvvaGRkRG+++eZDH9/1nd2am8uVEgHAA2zZEtUv33+n6Lyk8i8tLWnXrl368MMPFQgElM/n1dnZqcnJSUUikYd6jG3PfFOzs79dbwQARTQ3N+k3n35UdF7S0/5cLqfGxkYFAgFJUiAQUENDg3I5zuRAreMNP8CoksofjUa1sLCgfD4vScrn81pcXFQ0Gi1LOAD+Kan89fX1isViymQykqRMJqNYLPbQr/cBVE/J7/bfuHFDyWRS9+7dUygUUjqd1rZt2x76eN7wA/zh9Ybf10r9A62trbp48WKpDwOgwnjDDzCK8gNGUX7AKMoPGEX5AaMoP2AU5QeMovyAUZQfMIryA0ZRfsAoyg8YRfkBoyg/YBTlB4yi/IBRlB8wivIDRlF+wCjKDxhF+QGjKD9gFOUHjKL8gFGUHzCK8gNGUX7AKMoPGEX5AaNK/pZe2LIn+rzr/LXN/+M6b/73fyk6++ztH7oe+9nH11znf//zP3Odj+SuuM6tKbn88XhcwWBQdXV1kqT+/n51dXWVHAyAv8py5j9z5oza2trK8VAAKoTX/IBRZTnz9/f3y3EcdXR0qK+vT6FQqBwPC8BHJZ/5h4eHNTY2ppGRETmOo1QqVY5cAHxWcvmj0agkKRgMKpFIaGpqquRQAPxXUvnX1ta0uroqSXIcR+Pj44rFYmUJBsBfJb3mX1paUm9vr/L5vAqFglpbWzU4OFiubKiCS5Fvu87bNi+7zv9p9U9d5yPfWP828LHoC67zn7y503X+2kvFP4Ow/dr0ujI9zkoq/9atWzU6OlquLAAqiK0+wCjKDxhF+QGjKD9gFOUHjOKS3idQLLK16OxXf7PZ9dhfvev+2NXcEns1957r/K2eT13nbv/25ef/0vXYyHDWdf444swPGEX5AaMoP2AU5QeMovyAUZQfMIryA0axz/8E+migo+hsfsh9L/x7y78od5yK+WT5tuv8W+8W//zDlZ/+g+uxsXffKOlv1yLO/IBRlB8wivIDRlF+wCjKDxhF+QGjKD9gFPv8jyGvr8ne8Nc7is62X7N7t+VE3TNFZ1/7q++4HvvJ8kC541QdZ37AKMoPGEX5AaMoP2AU5QeMovyAUZQfMIp9/sfQ8Mc/cp2/2NFXoSS1xevzDy9/nFr3Y/9u/peu87WX3e8HUIv3/fc886fTacXjcW3fvl3Xrl27//uZmRn19PRo165d6unp0c2bN/3MCaDMPMu/c+dODQ8Pa8uWLX/w+8HBQSUSCU1MTCiRSOjIkSO+hQRQfp7l37Fjh6LR6B/8bmlpSdlsVt3d3ZKk7u5uZbNZLS8v+5MSQNmt6w2/XC6nxsZGBQIBSVIgEFBDQ4NyuVxZwwHwD+/2A0atq/zRaFQLCwvK5/OSpHw+r8XFxa+8PABQu9ZV/vr6esViMWUyGUlSJpNRLBZTJBIpazgA/vHc5z9+/LgmJyd1584dHTx4UOFwWJcvX9bRo0eVTCZ17tw5hUIhpdPpSuQ1wWu/2stI7kqZktQWr3Xx+vxDKbz28b/17qpvf9svnuUfGBjQwMBXb2TQ2tqqixcv+hIKgP94ww8wivIDRlF+wCjKDxhF+QGjuKS3BrXr69WO4Bu37bofv7yl6EyS/mTvP5b0tz97+4dFZ393Ys712JFc7V2SWyrO/IBRlB8wivIDRlF+wCjKDxhF+QGjKD9gFPv8Neg/9d8lHe+2l17q5b6xyFbX+UcDHa5zt7363//6fddjf/bc913nhzXjOv9k+bbr3BrO/IBRlB8wivIDRlF+wCjKDxhF+QGjKD9gFPv8NchrL/5fPW4jPfzxG0Vn2ecSrsf+s/7Cdf7d6R+4zr2c6Cj+ha6v5t4r6bHxaDjzA0ZRfsAoyg8YRfkBoyg/YBTlB4yi/IBR7PM/hiLD7veQ/92J4rP/mH6rpL/NNfVPDs/yp9NpTUxMaG5uTpcuXVJbW5skKR6PKxgMqq6uTpLU39+vrq4uf9MCKBvP8u/cuVMHDhzQiy+++JXZmTNn7v/PAMDjxbP8O3bsqEQOABVW0mv+/v5+OY6jjo4O9fX1KRQKlSsXAJ+t+93+4eFhjY2NaWRkRI7jKJVKlTMXAJ+tu/zRaFSSFAwGlUgkNDU1VbZQAPy3rvKvra1pdXVVkuQ4jsbHxxWLxcoaDIC/PF/zHz9+XJOTk7pz544OHjyocDisoaEh9fb2Kp/Pq1AoqLW1VYODg5XIC0mXIt9e97Fu31Evud9XX2If/0niWf6BgQENDAx85fejo6O+BAJQGXy8FzCK8gNGUX7AKMoPGEX5AaO4pLcGrf7ob13nn318zXX+Ykdf0ZnXbcH3nJhznV/5qfttw+deett1vv3atOsclcOZHzCK8gNGUX7AKMoPGEX5AaMoP2AU5QeMYp/fB7HIVtd5ou4Z17nXPr7XrbtL4fU5gGzPf7nOPW8N/g3u8FwrOPMDRlF+wCjKDxhF+QGjKD9gFOUHjKL8gFHs8/vA65r3Uwf+zXXu5z5+qbg195ODMz9gFOUHjKL8gFGUHzCK8gNGUX7AKMoPGMU+/zqV8jXZr+beK2OSyvK6VwEeH57lX1lZ0eHDh3Xr1i0Fg0E1NzcrlUopEoloZmZGyWRSd+/eVTgcVjqdVktLSwViAyiV59P+DRs26NChQ5qYmNClS5e0detWnTx5UpI0ODioRCKhiYkJJRIJHTlyxPfAAMrDs/zhcFidnZ33f25vb9f8/LyWlpaUzWbV3d0tSeru7lY2m9Xy8rJ/aQGUzSO94VcoFHThwgXF43Hlcjk1NjYqEAhIkgKBgBoaGpTL5XwJCqC8Hqn8x44d06ZNm7Rv3z6/8gCokId+tz+dTmt2dlZDQ0PauHGjotGoFhYWlM/nFQgElM/ntbi4qGg06mdeAGXyUOU/deqUpqendf78eQWDQUlSfX29YrGYMpmMdu/erUwmo1gspkgk4mvgx4HXJbu1zGsrz+ty5d//+v1yxoGPPMt//fp1DQ0NqaWlRXv37pUkNTU16ezZszp69KiSyaTOnTunUCikdDrte2AA5eFZ/meffVZXr1594Ky1tVUXL14seygA/uPjvYBRlB8wivIDRlF+wCjKDxjFJb3r9N3pHxSd/bijr4JJHs2e6POu85+8ubukx3++542SjkflcOYHjKL8gFGUHzCK8gNGUX7AKMoPGEX5AaPY51+nEx3Fb1bqtVfefuDrJf3tl+ILrvNNJ9a/1/6z577vOv/e8i/W/dioLZz5AaMoP2AU5QeMovyAUZQfMIryA0ZRfsCoDY7jONUMsO2Zb2p29rfVjFB2V9uec53/+fMF17nXPv3ay+73zj/788ais7f+91PXYz9Zvu06x+OjublJv/n0o6JzzvyAUZQfMIryA0ZRfsAoyg8YRfkBoyg/YJTn9fwrKys6fPiwbt26pWAwqObmZqVSKUUiEcXjcQWDQdXV1UmS+vv71dXV5XvoWrf92rT7f3DN4wGGS13DbInHwwLP8m/YsEGHDh1SZ2enJCmdTuvkyZN67bXXJElnzpxRW1ubvykBlJ3n0/5wOHy/+JLU3t6u+fl5X0MB8N8j3carUCjowoULisfj93/X398vx3HU0dGhvr4+hUKhsocEUH6P9IbfsWPHtGnTJu3bt0+SNDw8rLGxMY2MjMhxHKVSKV9CAii/hy5/Op3W7OysTp8+rY0bPz8sGo1KkoLBoBKJhKampvxJCaDsHupp/6lTpzQ9Pa3z588rGAxKktbW1pTP57V582Y5jqPx8XHFYjFfwwIoH8/yX79+XUNDQ2ppadHevXslSU1NTUomk+rt7VU+n1ehUFBra6sGBwd9DwygPLieH3hCcT0/gAei/IBRlB8wivIDRlF+wCjKDxhF+QGjKD9gFOUHjKL8gFGUHzCK8gNGUX7AqEe6jZcftmyJVjsC8ETy6lbVL+kFUB087QeMovyAUZQfMIryA0ZRfsAoyg8YRfkBoyg/YBTlB4yq+sd7JWlmZkbJZFJ3795VOBxWOp1WS0tLtWNJkuLxuILBoOrq6iR9/q3EXV1dFc+RTqc1MTGhubk5Xbp0SW1tbZJqY+2KZauFtVtZWdHhw4d169YtBYNBNTc3K5VKKRKJVH3t3LJVZO2cGrB//35ndHTUcRzHGR0ddfbv31/lRF964YUXnKtXr1Y7hnPlyhVnfn7+K3lqYe2KZauFtVtZWXE++OCD+z+//vrrziuvvOI4TvXXzi1bJdau6k/7l5aWlM1m1d3dLUnq7u5WNpvV8vJylZPVlh07dtz/VuQv1MraPShbrQiHw+rs7Lz/c3t7u+bn52ti7Yplq5SqP+3P5XJqbGxUIBCQJAUCATU0NCiXyykSiVQ53ef6+/vlOI46OjrU19enUChU7UiSWLtHVSgUdOHCBcXj8Zpbu/+f7Qt+r13Vz/y1bnh4WGNjYxoZGZHjOEqlUtWO9NiotbU7duyYNm3apH379lU1x4P8cbZKrF3Vyx+NRrWwsKB8Pi9JyufzWlxcrJmnkV/kCAaDSiQSmpqaqnKiL7F2Dy+dTmt2dlanT5/Wxo0ba2rt/jibVJm1q3r56+vrFYvFlMlkJEmZTEaxWKwmnraura1pdXVVkuQ4jsbHxxWLxaqc6kus3cM5deqUpqendfbsWQWDQUm1s3YPylaptauJm3ncuHFDyWRS9+7dUygUUjqd1rZt26odS7dv31Zvb6/y+bwKhYJaW1s1MDCghoaGimc5fvy4JicndefOHT399NMKh8O6fPlyTazdg7INDQ3VxNpdv35d3d3damlp0VNPPSVJampq0tmzZ6u+dsWyJZPJiqxdTZQfQOVV/Wk/gOqg/IBRlB8wivIDRlF+wCjKDxhF+QGjKD9g1P8BmA9nOdOyQ28AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = plt.imshow(X_train[0][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3,3), padding = \"same\",\n",
    "                activation = \"relu\", input_shape =(28, 28, 1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3,3), padding =\"same\",\n",
    "                activation = \"relu\"))\n",
    "model.add(MaxPool2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (5,5), padding = \"same\",\n",
    "                activation = \"relu\"))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(learning_rate=0.001, rho= 0.9, epsilon = 1e-08, decay = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= optimizer, loss= \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReduceLROnPlateau?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_decline = ReduceLROnPlateau(monitor= \"val_accuracy\",factor = .33 ,verbose = 1,patience = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.2224 - accuracy: 0.9873 - val_loss: 0.0392 - val_accuracy: 0.9931 - lr: 3.9063e-06\n",
      "Epoch 2/12\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0633 - accuracy: 0.9921 - val_loss: 0.0266 - val_accuracy: 0.9936 - lr: 3.9063e-06\n",
      "Epoch 3/12\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0360 - accuracy: 0.9931 - val_loss: 0.0238 - val_accuracy: 0.9938 - lr: 3.9063e-06\n",
      "Epoch 4/12\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0339 - accuracy: 0.9935 - val_loss: 0.0228 - val_accuracy: 0.9940 - lr: 3.9063e-06\n",
      "Epoch 5/12\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0292 - accuracy: 0.9938 - val_loss: 0.0220 - val_accuracy: 0.9936 - lr: 3.9063e-06\n",
      "Epoch 6/12\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0207 - accuracy: 0.9943 - val_loss: 0.0215 - val_accuracy: 0.9940 - lr: 3.9063e-06\n",
      "Epoch 7/12\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0219 - accuracy: 0.9945 - val_loss: 0.0213 - val_accuracy: 0.9938 - lr: 3.9063e-06\n",
      "Epoch 8/12\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0272 - accuracy: 0.9944 - val_loss: 0.0208 - val_accuracy: 0.9940 - lr: 3.9063e-06\n",
      "Epoch 9/12\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0229 - accuracy: 0.9944 - val_loss: 0.0204 - val_accuracy: 0.9938 - lr: 3.9063e-06\n",
      "Epoch 10/12\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0190 - accuracy: 0.9949 - val_loss: 0.0210 - val_accuracy: 0.9940 - lr: 3.9063e-06\n",
      "Epoch 11/12\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0189 - accuracy: 0.9949 - val_loss: 0.0206 - val_accuracy: 0.9940 - lr: 3.9063e-06\n",
      "Epoch 12/12\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0199 - accuracy: 0.9942 - val_loss: 0.0202 - val_accuracy: 0.9940 - lr: 3.9063e-06\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 12, verbose = 1,batch_size=batch, validation_data=(X_val, y_val), \n",
    "                    callbacks=[learning_rate_decline])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_augmentation = ImageDataGenerator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_augmentation = ImageDataGenerator(\n",
    "                            rotation_range=15,\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1,\n",
    "                            brightness_range=None,\n",
    "                            shear_range=0.0,\n",
    "                            zoom_range=0.1,\n",
    "                            horizontal_flip=False,\n",
    "                            vertical_flip=False,\n",
    "                            validation_split=0.0,\n",
    "                            dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "378/378 [==============================] - 13s 35ms/step - loss: 0.0797 - accuracy: 0.9792 - val_loss: 0.0279 - val_accuracy: 0.9929 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "378/378 [==============================] - 13s 35ms/step - loss: 0.0781 - accuracy: 0.9798 - val_loss: 0.0683 - val_accuracy: 0.9902 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "378/378 [==============================] - 13s 36ms/step - loss: 0.0780 - accuracy: 0.9799 - val_loss: 0.0356 - val_accuracy: 0.9936 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "378/378 [==============================] - 15s 39ms/step - loss: 0.0802 - accuracy: 0.9797 - val_loss: 0.0263 - val_accuracy: 0.9933 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "378/378 [==============================] - 13s 35ms/step - loss: 0.0782 - accuracy: 0.9797 - val_loss: 0.0467 - val_accuracy: 0.9910 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "378/378 [==============================] - 14s 36ms/step - loss: 0.0769 - accuracy: 0.9813 - val_loss: 0.0475 - val_accuracy: 0.9945 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "378/378 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.9797\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "378/378 [==============================] - 14s 36ms/step - loss: 0.0836 - accuracy: 0.9797 - val_loss: 0.0605 - val_accuracy: 0.9893 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "378/378 [==============================] - 14s 38ms/step - loss: 0.0618 - accuracy: 0.9838 - val_loss: 0.0517 - val_accuracy: 0.9919 - lr: 5.0000e-04\n",
      "Epoch 9/30\n",
      "378/378 [==============================] - 14s 36ms/step - loss: 0.0571 - accuracy: 0.9851 - val_loss: 0.0405 - val_accuracy: 0.9933 - lr: 5.0000e-04\n",
      "Epoch 10/30\n",
      "378/378 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 0.9856\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "378/378 [==============================] - 13s 35ms/step - loss: 0.0561 - accuracy: 0.9856 - val_loss: 0.0531 - val_accuracy: 0.9924 - lr: 5.0000e-04\n",
      "Epoch 11/30\n",
      "378/378 [==============================] - 14s 37ms/step - loss: 0.0465 - accuracy: 0.9875 - val_loss: 0.0532 - val_accuracy: 0.9921 - lr: 2.5000e-04\n",
      "Epoch 12/30\n",
      "378/378 [==============================] - 14s 37ms/step - loss: 0.0475 - accuracy: 0.9876 - val_loss: 0.0330 - val_accuracy: 0.9936 - lr: 2.5000e-04\n",
      "Epoch 13/30\n",
      "378/378 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 0.9879\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "378/378 [==============================] - 14s 38ms/step - loss: 0.0457 - accuracy: 0.9879 - val_loss: 0.0406 - val_accuracy: 0.9929 - lr: 2.5000e-04\n",
      "Epoch 14/30\n",
      "378/378 [==============================] - 14s 36ms/step - loss: 0.0409 - accuracy: 0.9892 - val_loss: 0.0918 - val_accuracy: 0.9910 - lr: 1.2500e-04\n",
      "Epoch 15/30\n",
      "378/378 [==============================] - 14s 36ms/step - loss: 0.0418 - accuracy: 0.9880 - val_loss: 0.0703 - val_accuracy: 0.9926 - lr: 1.2500e-04\n",
      "Epoch 16/30\n",
      "378/378 [==============================] - ETA: 0s - loss: 0.0433 - accuracy: 0.9884\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "378/378 [==============================] - 13s 35ms/step - loss: 0.0433 - accuracy: 0.9884 - val_loss: 0.0726 - val_accuracy: 0.9917 - lr: 1.2500e-04\n",
      "Epoch 17/30\n",
      "378/378 [==============================] - 15s 39ms/step - loss: 0.0385 - accuracy: 0.9891 - val_loss: 0.0669 - val_accuracy: 0.9926 - lr: 6.2500e-05\n",
      "Epoch 18/30\n",
      "378/378 [==============================] - 14s 37ms/step - loss: 0.0376 - accuracy: 0.9895 - val_loss: 0.1142 - val_accuracy: 0.9905 - lr: 6.2500e-05\n",
      "Epoch 19/30\n",
      "377/378 [============================>.] - ETA: 0s - loss: 0.0367 - accuracy: 0.9897\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "378/378 [==============================] - 13s 35ms/step - loss: 0.0367 - accuracy: 0.9897 - val_loss: 0.1359 - val_accuracy: 0.9907 - lr: 6.2500e-05\n",
      "Epoch 20/30\n",
      "378/378 [==============================] - 14s 36ms/step - loss: 0.0356 - accuracy: 0.9904 - val_loss: 0.1719 - val_accuracy: 0.9893 - lr: 3.1250e-05\n",
      "Epoch 21/30\n",
      "378/378 [==============================] - 15s 39ms/step - loss: 0.0372 - accuracy: 0.9897 - val_loss: 0.2091 - val_accuracy: 0.9883 - lr: 3.1250e-05\n",
      "Epoch 22/30\n",
      "377/378 [============================>.] - ETA: 0s - loss: 0.0402 - accuracy: 0.9898\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "378/378 [==============================] - 14s 38ms/step - loss: 0.0402 - accuracy: 0.9898 - val_loss: 0.1369 - val_accuracy: 0.9905 - lr: 3.1250e-05\n",
      "Epoch 23/30\n",
      "378/378 [==============================] - 13s 36ms/step - loss: 0.0370 - accuracy: 0.9900 - val_loss: 0.1476 - val_accuracy: 0.9895 - lr: 1.5625e-05\n",
      "Epoch 24/30\n",
      "378/378 [==============================] - 14s 36ms/step - loss: 0.0355 - accuracy: 0.9898 - val_loss: 0.1472 - val_accuracy: 0.9900 - lr: 1.5625e-05\n",
      "Epoch 25/30\n",
      "378/378 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.9897\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "378/378 [==============================] - 15s 39ms/step - loss: 0.0351 - accuracy: 0.9897 - val_loss: 0.1519 - val_accuracy: 0.9902 - lr: 1.5625e-05\n",
      "Epoch 26/30\n",
      "378/378 [==============================] - 14s 37ms/step - loss: 0.0370 - accuracy: 0.9900 - val_loss: 0.1483 - val_accuracy: 0.9900 - lr: 7.8125e-06\n",
      "Epoch 27/30\n",
      "378/378 [==============================] - 13s 36ms/step - loss: 0.0349 - accuracy: 0.9906 - val_loss: 0.1440 - val_accuracy: 0.9902 - lr: 7.8125e-06\n",
      "Epoch 28/30\n",
      "377/378 [============================>.] - ETA: 0s - loss: 0.0334 - accuracy: 0.9905\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "378/378 [==============================] - 14s 36ms/step - loss: 0.0334 - accuracy: 0.9905 - val_loss: 0.1422 - val_accuracy: 0.9898 - lr: 7.8125e-06\n",
      "Epoch 29/30\n",
      "378/378 [==============================] - 14s 37ms/step - loss: 0.0346 - accuracy: 0.9903 - val_loss: 0.1457 - val_accuracy: 0.9895 - lr: 3.9063e-06\n",
      "Epoch 30/30\n",
      "378/378 [==============================] - 15s 39ms/step - loss: 0.0351 - accuracy: 0.9901 - val_loss: 0.1447 - val_accuracy: 0.9898 - lr: 3.9063e-06\n"
     ]
    }
   ],
   "source": [
    "new = model.fit_generator(\n",
    "    digit_augmentation.flow(X_train, y_train, batch_size = batch),\n",
    "    steps_per_epoch= X_train.shape[0]//batch,\n",
    "    epochs=30,\n",
    "    verbose=1,\n",
    "    callbacks=[learning_rate_decline],\n",
    "    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub[\"ImageId\"] = np.arange(1, len(pred)+1)\n",
    "sub[\"Label\"] = np.dot(np.round(pred),np.arange(0,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[\"Label\"] = sub[\"Label\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"sub.csv\", index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
